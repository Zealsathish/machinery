# Internal consistency of system descriptions

There are cases where different parts of the system description describe the same aspect of a system in different ways. When a system description is generated by an inspection of an existing system, all parts of the description are consistent. But when modifying a description it can happen that inconsistencies are created by modifying different parts of the description in different ways. This document describes our approach how to handle the internal consistency of system descriptions.


## Examples of inconsistencies

When a system is inspected some data is duplicated. This happens for example when multiple scopes handle and store the same information.
An example is repositories: The repositories are queried and then stored in `manifest.json` by the repositories scope.
Additionally the files in `/etc/zypp/repos.d` contain the same information and are handled by unmanaged-files.
Another example are users and groups, which are handled by the scopes 'users' and 'groups'. The files `/etc/passwd`,
`/etc/shadow`, and `/etc/group` contain the same information. Configuration files are handled by the scope config-files.

Duplication of this data leads to problems like the same repository appearing multiple times on a build image because it's applied by the unmanaged-files and the repositories scope.

Another example are mount points. They are present in the description as the files where this information is contained. For changing this information or using it from other tools it would be desirable to have this information available in a more abstract form as well.


## Current Approach

The current approach is to avoid inconsistencies by filtering files duplicating information which is stored in the manifest. This is done either at inspection or on export.

During inspection for some scopes (e.g. for users and groups) all the information contained in the configuration files (`/etc/passwd` and `/etc/group` in the example) is put into the manifest. The file where the information is coming from then is not extracted by the inspection.

For other cases duplicated information contained in the manifest is filtered out on export, when an image is built, or a kiwi or AutoYaST profile is exported. For example the yum configuration files are not exported, but new ones are created based on the information in the manifest. The list of these files is hard-coded in the exporter.

In a third case there is information in the system description, which is only used for information, but ignored otherwise (the diffs of config files relative to the version coming from its package).

So, the current approach tries not to apply config files when they are already covered on a more abstract level. This avoids duplication of data in some cases, but it has some issues:

* If extraction of information from a configuration file to the manifest is not 100% complete or accurate, information is lost.
* If the list of files filtered on export is not complete (for example when there is plugin configuration at a different location, the place where configuration is held is modified, additional information is fed in from a sysconfig file, or configuration is determined dynamically), there can be inconsistencies or broken setups in the exported data.
* There is no well-defined order how configuration is applied (in some cases the file overrides the manifest, in others it doesn't, in other cases information is not applied at all)

## Abstraction levels of configuration

The underlying issue is that configuration can be represented on different levels of abstraction:

### Raw data

Looking at configuration files as opaque objects preserves all the state, but doesn't provide insight into the actual configuration. This would be the represenation as raw data without any processing.

### Parsed raw data

If the format of a configuration file is known, it can be parsed into a more high-level representation maintaining all information in a generic way (e.g. parsing an INI-style config file into a JSON representation). This can provide some generic insight into the configuration, but requires the user to still have knowledge about the details of the configuration and how it is represented. There also is a chance that some minor information is lost, when the parser is not perfect (e.g. comments, ordering of entries, etc.)

### Extracted information

For known configuration it's possible to explicitly extract the relevant configuration information from files and store it in a more general abstracted format in the manifest. This gives a high degree of insight, possibly across different ways and tools to manage the configuration. It is hard to make sure that all information is extracted, though. Especially if configuration changes, even a complete extraction might become inconsistent, without the user noticing it.

### Declarative configuration

The highest level of abstraction would be to have a declaration of intended result instead of concrete configuration settings. For example a service can be described like a black box (e.g. webserver listening on port 80) or in detail (e.g. apache's configuration files). This declarative configuration would be on the level which typically is handled by configuration management systems (such as Puppet or SaltStack). It might be hard or even impossible to extract information on this level from a system as it can require information about the intent of configuration, which might not be stored in the system itself. It often would be the desired level of abstraction when defining the configuration of a system. Typically it would be stored outside of the systems itself.


## Processing configuration

To get higher levels of abstraction it is necessary to process configuration files and data.

One challenge is to correctly process configuration. In some cases the only reliable way how to do that is to use the native tools using the configuration. As a middle ground existing abstractions of parsers, such as Augeas or what is in YaST could be helpful.

Another challenge is to where to process the data. In some cases it might be necessary to do that in the environment of the running system, in other cases, extracted data is enough.


## Use cases

Which level of abstraction is useful depends on the use case. Examples:

### Configuration discovery

When analyzing a system, especially when trying to figure out what an unknown system does, all levels of abstraction are helpful. Even the same data on different levels can be helpful. The more data is available the easier it is for the user to find and judge the configuration of the system.

### Replication of a system

When recovering a system or when replicating it in general, a higher abstraction is not necessary. Using raw data encapsulating the state of a system in its native form is the most reliable way to achieve an exact replication.

### Migration

For a migration use case it depends on what level of abstraction the migration is taking place. When it is a low-level migration such as migrating a physical to a virtual system, the use case is closer to a replication of a system. When it is on a higher level, e.g. when moving a service from one operating system to another, the lower level configuration might simply not work because the config file format could have changed or even a different tool used which provides the same service (e.g. Lighttpd instead of Apache). But correct configuration can be deduced from the higher level representation.

For all migration use cases it is important that the result is in a consistent state, so that the target system is functional in itself.

### Editing a system description

When modifying a system description manually or programmatically, it depends on the knowledge of the user, what abstraction level is most convenient. If a user knows the format of a configuration file, it might be easiest to edit that directly. In other cases it might be more convenient to edit the abstract description, so that it can be used in a more abstract way and for example be applied to different target systems.

There can't be a clear preference here. The challenge is to avoid problems caused by inconsistencies of information on different levels.


## Requirements

In the context of the internal consistency of system description we have a number of requirements:

* No data should be lost without the user being aware of it or explicitly desiring it.
* For gaining insight into a system it should be easy to get data, or add new functionality to gather additional data, or process existing data to get more insight.
* A system description obtained by inspection should be usable in different use cases, which might not be known yet during inspection. This means we don't know which level of abstraction we will need.
* There are more ways to get a system description besides inspection:
  * Creation of a system description using an editor
  * Composition of a system description using hierarchical templates
  * Import from a different format (e.g. KIWI, AutoYaST)
* When a description is applied or exported the result should be consistent and working.
* It should be transparent what happens during inspection and export, so that the user is able to diagnose and fix problems.
* The user should be in control of how configuration is applied and which level of abstraction is used depending on the use case.


## Concept

This section describes the concept how we address the issue of consistency of the system description and how we provide the necessary tools for the user to handle this data. It has two main goals:

* Make it transparent to the user what is happening and why
* Give user control to adapt the tool to their needs and use cases

### Duplication of data

With scopes covering the same data from different views, e.g. a configuration file in the config-files scope, and the data extraced from the file in the manifest, some data is duplicated. This gives the full picture and can be useful to the user. So the basic approach is to not try to prevent duplication of data, but make it transparent and controllable what effect the duplication has.

This makes writing scopes easier, because they can do simple extraction of data without having to care about effects on other scopes, provided it is clearly defined how the data is used.

### Sequence of operations

When using Machinery each invocation results in a sequence of operations which are applied to a give set of scopes. The exact sequence and the set of scopes define the result. For an inspection that would be applying global filters, then inspecting the data belonging to the scopes, and storing it to a description. For an image build that would be reading the description, exporting the data for each scope, applying export filters, and running the build.

For inspection the sequence does not matter, it only matters which scopes are used, but the result is independent of what is done when. Scopes never require exclusion of files, not even when the files are read and their data is extracted into the manifest. The duplication of information is handled later.

For export it does matter, if data which is present in the manifest part for a scope is applied first or the same data stored in a file in a file scope is applied first. If the file is applied first and then the manifest, the file is overwritten.

The default sequence is to first apply the files and then apply the data from the manifest. The user can prevent that the manifest data is overwriting the file data by excluding the scope which has the manifest data from the export. This gives full control about the result.

To make it easier for users to achieve commonly required results, it might make sense to exclude some scopes from the export by default.

### Definition of scopes

To make it explicit what dependencies and implications a scope has we add an explicit definition of a scope. This is a YAML file, which defines, what filters to apply, what belongs to the scope and other meta data.

#### Filter definition

An example for a minimal filter definition based on the current functionality is a file `scopes/repositories.yam` with the content:

```yaml
filters:
  export:
    /unmanaged_files/files/name=/etc/zypp/repos.d/*
```

This defines the filter, which is currently hard-coded in the export code.

By moving the filters to the scope definitions, the context why they are needed is preserved. The code which needs them, can simply iterate over the scope definitions and add all the filters defined there to the list of filters effectively to be applied.

Filters can gradually be moved from hard-coded central locations to the scopes. The scope-specific inspection filters should be removed.

#### Name

The scope is displayed in the UI using the implied name determined from the source code files. To make it easier to define user-friendly names and also make the context of the scope definitions explicit it has an entry defining the display name, e.g.:

```yaml
name: Users
```

#### Additional attributes

The scope definition can be used to store additional attributes in the future, e.g. information about if a scope is used in export by default, dependencies between scopes, references to the other files which belong to the scope, etc.

The following example illustrates the general ideas. Its values don't make sense as is, and the attributes might have to be named and structured differently. It needs to be refined before it can be implemented.

```yaml
name: Example scope

filters:
  export:
    /unmanaged_files/files/name=/etc/example/conf.d/*

active:
  export: false

files:
  schema: plugins/schema/v3/system-description-example.schema.json
  model: plugins/model/example_model.rb
  inspect: plugins/inspect/example_inspector.rb
  show: plugins/show/example_renderer.rb
  docs: plugins/docs/example.md
```

### Scopes as plugins

When it's clear how the data of scopes is used and it's not a problem if additional possibly duplicated data is present, it makes sense to make it as easy as possible to add scopes just to get more information about a system on inspection. This can be solved by providing new scopes as plugins.

With the scope being the central unit, the files the scope consists of should be structured in a more central way. The easiest solution would be to have a directory per scope in the `scopes` directory, which at least contains a scope definition file as described above. Additional files such as a model, an inspector, etc can be added and either be automatically recognized based on naming convention or explicitly referenced by the `files` section proposed for the scope definition file.

### Analysis as scope

The data which is put into the manifest of the description usually is extracted from files, which in many cases are also present in the system description.

In principle this can be done at inspection time but also later. For example the user scope could also instead of creating the manifest data during inspection just extract the `/etc/passwd` file and run the analysis of what users are in there later.

In this sense the operations of the `analyze` and the `inspect` command are very similar and they could be unified by making the `analyze` operations normal scopes which are flagged as operating on an existing description, not being constructed at inspection time. For convenience they could be run at inspection, though.

As an option for the future the `analyze` command could be replaced by introducing corresponding scopes which are marked as being able to run on a description. Some scopes such as `users` or `groups` could be marked in the same way. As a result the user would have full control about what data is extracted (possibly duplicated), and what operations are applied on inspection, simply by providing a list of scopes.

### Validation of consistency

When the data in the manifest can be derived from file data in the description, it can be run and checked at any point in time. It can also be used to check if the data in the manifest is consistent with the data in files. This could be exposed to the user in the future in form of a validation command, which detects inconsistencies.

### Summary

The core characteristics of the concept for dealing with the consistency of the system description can be summarized as follows:

* Duplication of data is accepted because it can help to provide additional insight to the user.
* Implications and dependencies of a scope are expressed in a scope definition file.
* Data from file scopes is applied before data from the manifest is applied. The user can control what data is applied by defining which scopes are used.

Future refinements include:

* Structure scope plugins in individual directories, which contain everything which belongs to the scope.
* Possibly move analyze operations to scopes.
* Provide a command to validate consistency of data in a system description.
